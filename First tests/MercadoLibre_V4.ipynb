{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selenium is a web testing library. It is used to automate browser activities.\n",
    "from selenium import webdriver\n",
    "#Beautiful Soup is a Python package for parsing HTML and XML documents. \n",
    "#It creates parse trees that is helpful to extract the data easily.\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "#Manage files and directories\n",
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to detect whether or not the excel file was created\n",
    "def CreateFile(CFdf,sheetname):\n",
    "    print (\"File exists:\"+str(path.exists('WebCheck.xlsx')))\n",
    "    if  not(path.exists('WebCheck.xlsx')):\n",
    "        # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "        writer = pd.ExcelWriter('WebCheck.xlsx', engine='xlsxwriter')\n",
    "    else:\n",
    "        writer = pd.ExcelWriter('WebCheck.xlsx', engine='openpyxl')\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook('WebCheck.xlsx')\n",
    "        # copy existing sheets\n",
    "        writer.sheets = dict((ws.title, ws) for ws in writer.book.worksheets)\n",
    "        # read existing file\n",
    "        reader = pd.read_excel('WebCheck.xlsx')\n",
    "        # write out the new sheet\n",
    "        \n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    CFdf.to_excel(writer,sheet_name=sheetname,index=False)\n",
    "    print(\"saved:\"+sheetname)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Chrome with chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check vulnerability in port 9515 due to selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\ChromeDriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands={'lg':169,'bgh':169,'samsung':179,'sony':179,'electrolux':169,'motorola':155,'huawei':179,'philips':179}\n",
    "#brands={'samsung':179}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tienda.mercadolibre.com.ar/lg\n",
      "File exists:False\n",
      "saved:lg\n",
      "https://tienda.mercadolibre.com.ar/bgh\n",
      "File exists:True\n",
      "saved:bgh\n",
      "2\n",
      "https://tienda.mercadolibre.com.ar/samsung\n",
      "https://listado.mercadolibre.com.ar/_Desde_49_Tienda_samsung\n",
      "File exists:True\n",
      "saved:samsung\n",
      "2\n",
      "https://tienda.mercadolibre.com.ar/sony\n",
      "https://listado.mercadolibre.com.ar/_Desde_49_Tienda_sony\n",
      "File exists:True\n",
      "saved:sony\n",
      "2\n",
      "https://tienda.mercadolibre.com.ar/electrolux\n",
      "https://listado.mercadolibre.com.ar/_Desde_49_Tienda_electrolux\n",
      "File exists:True\n",
      "saved:electrolux\n",
      "https://tienda.mercadolibre.com.ar/motorola\n",
      "File exists:True\n",
      "saved:motorola\n",
      "https://tienda.mercadolibre.com.ar/huawei\n",
      "File exists:True\n",
      "saved:huawei\n",
      "8\n",
      "https://tienda.mercadolibre.com.ar/philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_49_Tienda_philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_97_Tienda_philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_145_Tienda_philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_193_Tienda_philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_241_Tienda_philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_289_Tienda_philips\n",
      "https://listado.mercadolibre.com.ar/_Desde_337_Tienda_philips\n",
      "File exists:True\n",
      "saved:philips\n"
     ]
    }
   ],
   "source": [
    "#1st stage, looking for brands\n",
    "for NextBrand in brands:\n",
    "    \n",
    "    products=[] #List to store name of the product\n",
    "    prices=[] #List to store price of the product\n",
    "    UrlAux=\"https://tienda.mercadolibre.com.ar/\"+NextBrand\n",
    "    driver.get(UrlAux)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "   # print(soup.find('ul',attrs={'class':'andes-pagination'}).prettify())\n",
    "\n",
    "    TotalNum=-1\n",
    "    if bool(soup.find('ul',attrs={'class':'andes-pagination'}))==True:\n",
    "        PagNum=soup.find('ul',attrs={'class':'andes-pagination'})\n",
    "        TotalNum=len(PagNum.findAll('a'))-1\n",
    "        print(TotalNum)\n",
    "\n",
    "    #TotalNum has the total number of how many pages are. every page has 48 elements\n",
    "    #If TotalNum=0 means that all products are in one page only.\n",
    "    if TotalNum<0:\n",
    "        TotalNum=1\n",
    "   \n",
    "    #2nd stage, to browse in all pages more then 48 products each.\n",
    "    for i in  range(TotalNum):\n",
    "        if i>0 :\n",
    "            # Creating the URL based on informartion from web page\n",
    "            UrlAux=\"https://listado.mercadolibre.com.ar/_Desde_\"+str((1+((i)*48)))+\"_Tienda_\"+NextBrand\n",
    "            driver.get(UrlAux)\n",
    "            content = driver.page_source\n",
    "            soup = BeautifulSoup(content)\n",
    "\n",
    "        print(UrlAux)\n",
    "        #print( soup.findAll('section',attrs={'class':'results grid'}))\n",
    "        #3rd  stage, looking for name and price\n",
    "        for a in soup.findAll('div',attrs={'class':'item__info'}):\n",
    "            name=a.find('span', attrs={'class':'main-title'})\n",
    "            price=a.find('div', attrs={'class':'item__price'})\n",
    "            products.append(name.text)\n",
    "            prices.append(price.text)\n",
    "        #print(products)\n",
    "    df = pd.DataFrame({'Product Name':products,'Price':prices}) \n",
    "\n",
    "    CreateFile(df,NextBrand)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
